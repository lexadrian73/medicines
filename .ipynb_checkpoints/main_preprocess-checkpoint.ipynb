{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec1e946c-c32f-4c13-8985-f1d93c0b7734",
   "metadata": {},
   "source": [
    "## Read DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00156405-9af2-4df1-a35d-dad8e7fb079e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ruta_archivo = \"data/abstracts.csv\"\n",
    "df_r = pd.read_csv(ruta_archivo, index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b725caa-74c9-4428-9b5b-bba96f50ab0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Papers 113008\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['cell_line', 'pubmedid', 'title', 'abstract'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numero_filas = df_r.shape[0]\n",
    "print(\"Papers\", numero_filas)\n",
    "df_r.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cbef8be-18bb-41bd-8d8c-0109dd9c3a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Limitar dataset \n",
    "df = df_r.head(130)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302b5d82-d2ab-42f3-aeac-d5e50c1cae3a",
   "metadata": {},
   "source": [
    "## Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bf7675b-833d-4339-90df-db3b4fec4f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     cell_line  pubmedid                                              title  \\\n",
      "0    CVCL_0028  33040078  Splicing factor SF3B1 promotes endometrial can...   \n",
      "1    CVCL_0028  34476599  Sirtuin 2 promotes cell stemness and MEK/ERK s...   \n",
      "2    CVCL_0028  35401936  Role of the prorenin receptor in endometrial c...   \n",
      "3    CVCL_0028  32431202  NLRC5 promotes cell migration and invasion by ...   \n",
      "4    CVCL_0028  24526410  GRP78 mediates cell growth and invasiveness in...   \n",
      "..         ...       ...                                                ...   \n",
      "125  CVCL_0136  30104528  Berberine Inhibits Human Melanoma A375.S2 Cell...   \n",
      "126  CVCL_0136  29164214  Withapubesides A-D: natural inducible nitric o...   \n",
      "127  CVCL_0136  19252325  Cytotoxic prenylated flavonoids from the stem ...   \n",
      "128  CVCL_0138  34452453  Efficient Transendothelial Migration of Latent...   \n",
      "129  CVCL_0138  34985653  Jurkat-Derived (J-Lat, J1.1, and Jurkat E4) an...   \n",
      "\n",
      "                                              abstract  \\\n",
      "0    Although endometrial cancer is the most common...   \n",
      "1    Sirtuin 2 (SIRT2) is functionally important in...   \n",
      "2    Endometrial cancer is the most diagnosed gynec...   \n",
      "3    NOD-like receptor family caspase recruitment d...   \n",
      "4    Recent studies have indicated that endoplasmic...   \n",
      "..                                                 ...   \n",
      "125  Many studies have demonstrated that berberine ...   \n",
      "126  Four new steroid glycosides, withapubesides A-...   \n",
      "127  Five new prenylated flavonoids, maackiaflavano...   \n",
      "128  A small fraction of HIV-1-infected T cells for...   \n",
      "129  The introduction of combination antiretroviral...   \n",
      "\n",
      "                                            abstract_p  \n",
      "0    although endometrial cancer common cancer fema...  \n",
      "1    sirtuin sirt2 functionally important cancer pr...  \n",
      "2    endometrial cancer diagnosed gynecological mal...  \n",
      "3    nod like receptor family caspase recruitment d...  \n",
      "4    recent study indicated endoplasmic reticulum s...  \n",
      "..                                                 ...  \n",
      "125  many study demonstrated berberine inhibited ce...  \n",
      "126  four new steroid glycoside withapubesides isol...  \n",
      "127  five new prenylated flavonoid maackiaflavanone...  \n",
      "128  small fraction hiv infected cell form populati...  \n",
      "129  introduction combination antiretroviral therap...  \n",
      "\n",
      "[130 rows x 5 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sistemas\\AppData\\Local\\Temp\\ipykernel_14184\\3096959392.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['abstract_p'] = df['abstract'].apply(preprocess_text)\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    tokens = [word for word in tokens if not re.match(r'\\d+', word)]\n",
    "    processed_text = ' '.join(tokens)\n",
    "    return processed_text\n",
    "\n",
    "df['abstract_p'] = df['abstract'].apply(preprocess_text)\n",
    "#df.to_csv('data/abstracts.csv', index=False)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a264559-351c-4a0f-b2b4-c4c886bc46fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "associated\n"
     ]
    }
   ],
   "source": [
    "a = \"associated\"\n",
    "print(preprocess_text(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c00919d-6d22-4674-a1bc-4bcc42363361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "unique_values = df['cell_line'].unique()\n",
    "print(len(unique_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b75192a-53f0-4924-9c23-e666ece16d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sistemas\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import OneClassSVM\n",
    "from scipy.spatial import distance\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "corpus = df['abstract_p']\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_tfidf = vectorizer.fit_transform(corpus)\n",
    "\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "dictionary = {i: feature_name for i, feature_name in enumerate(feature_names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7e2274d0-ebf8-4f72-9ea3-56d26a03df54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categoría: CVCL_0081\n",
      "Radio: 0.8997990642468928\n",
      "Cantidad de documentos en el centroide: 13\n",
      "Centro de la esfera: [[0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "Categoría: CVCL_0082\n",
      "Radio: 0.8783281141968601\n",
      "Cantidad de documentos en el centroide: 7\n",
      "Centro de la esfera: [[0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "Categoría: CVCL_0028\n",
      "Radio: 0.9231832826502782\n",
      "Cantidad de documentos en el centroide: 13\n",
      "Centro de la esfera: [[0.         0.         0.         ... 0.         0.00436579 0.00683307]]\n",
      "\n",
      "Categoría: CVCL_0110\n",
      "Radio: 0.9301525976172133\n",
      "Cantidad de documentos en el centroide: 13\n",
      "Centro de la esfera: [[0.         0.00345127 0.         ... 0.         0.         0.        ]]\n",
      "\n",
      "Categoría: CVCL_0113\n",
      "Radio: 0.8948901635178277\n",
      "Cantidad de documentos en el centroide: 13\n",
      "Centro de la esfera: [[0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "Categoría: CVCL_0115\n",
      "Radio: 0.9097923308791559\n",
      "Cantidad de documentos en el centroide: 13\n",
      "Centro de la esfera: [[0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "Categoría: CVCL_0080\n",
      "Radio: 0.9310391619310289\n",
      "Cantidad de documentos en el centroide: 13\n",
      "Centro de la esfera: [[0.         0.         0.         ... 0.         0.00594045 0.00648101]]\n",
      "\n",
      "Categoría: CVCL_0107\n",
      "Radio: 0.9179621039393151\n",
      "Cantidad de documentos en el centroide: 13\n",
      "Centro de la esfera: [[0.00610101 0.         0.         ... 0.         0.         0.00354093]]\n",
      "\n",
      "Categoría: CVCL_0128\n",
      "Radio: 0.8400466899035995\n",
      "Cantidad de documentos en el centroide: 4\n",
      "Centro de la esfera: [[0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "Categoría: CVCL_0135\n",
      "Radio: 0.8946061056160539\n",
      "Cantidad de documentos en el centroide: 13\n",
      "Centro de la esfera: [[0.         0.         0.100542   ... 0.         0.         0.00403741]]\n",
      "\n",
      "Categoría: CVCL_0138\n",
      "Radio: 0.6082740520434031\n",
      "Cantidad de documentos en el centroide: 2\n",
      "Centro de la esfera: [[0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "Categoría: CVCL_0136\n",
      "Radio: 0.8974736187503479\n",
      "Cantidad de documentos en el centroide: 13\n",
      "Centro de la esfera: [[0.         0.         0.         ... 0.0093635  0.         0.03693564]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "corpus = df['abstract_p'].tolist()  # Obtener la lista de documentos\n",
    "\n",
    "# Crear el objeto vectorizador TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_tfidf = vectorizer.fit_transform(corpus)\n",
    "\n",
    "category_labels = df['cell_line'].tolist()  # Convertir la columna a una lista\n",
    "document_indices = df.index.tolist()\n",
    "\n",
    "# Número de categorías\n",
    "num_categories = 12\n",
    "\n",
    "# Diccionarios para almacenar los centroides y radios por categoría\n",
    "category_centroids = {}\n",
    "category_radii = {}\n",
    "category_document_counts = {}\n",
    "\n",
    "for category in set(category_labels):\n",
    "    # Obtener los índices de los documentos correspondientes a la categoría actual\n",
    "    category_indices = [i for i, label in enumerate(category_labels) if label == category]\n",
    "\n",
    "    if len(category_indices) > 0:\n",
    "        # Obtener los documentos correspondientes a la categoría actual\n",
    "        category_documents = X_tfidf[category_indices]\n",
    "\n",
    "        # Entrenar el modelo SVDD para la categoría actual\n",
    "        model = OneClassSVM(gamma='scale')\n",
    "        model.fit(category_documents)\n",
    "\n",
    "        # Obtener los vectores de soporte del modelo\n",
    "        support_vectors = model.support_vectors_\n",
    "\n",
    "        # Calcular el centroide\n",
    "        centroid = np.mean(support_vectors, axis=0)\n",
    "        category_centroids[category] = centroid\n",
    "\n",
    "        # Calcular el radio (distancia promedio entre los vectores de soporte y el centroide)\n",
    "        distances = np.linalg.norm(support_vectors - centroid, axis=1)\n",
    "        radius = np.mean(distances)\n",
    "        category_radii[category] = radius\n",
    "\n",
    "        # Contar la cantidad de documentos en el centroide\n",
    "        document_count = len(category_indices)\n",
    "        category_document_counts[category] = document_count\n",
    "\n",
    "# Imprimir los resultados por categoría\n",
    "for category in category_centroids:\n",
    "    centroid = category_centroids[category]\n",
    "    radius = category_radii[category]\n",
    "    document_count = category_document_counts[category]\n",
    "\n",
    "    print(\"Categoría:\", category)\n",
    "    print(\"Radio:\", radius)\n",
    "    print(\"Cantidad de documentos en el centroide:\", document_count)\n",
    "    print(\"Centro de la esfera:\", centroid)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36050ecb-ebaf-479e-afcf-0d291dfe9ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tengo un data set con 130 filas, son dos columanas con texto y la otra con una categoria, con 12 categorias\n",
    "c1, c2, ..., c12 y los textos pueden estar c1 n doc, c2 m docs, etc. los documentos ya estas limpiados, lo que necesito es \n",
    "que se le aplique TF IDF para ponerlos en un espcio vectorial para luego entrenar un modelo SVDD, entonce divide la data en test \n",
    "y train de ahi aplicar 12 hyperesferas de ahi obetber las centros a de las 12 hyperesferas y los radios de cada esfera haz el coddigo en python "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "945ef350-2162-41b9-9867-d35f1c9a2559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo SVDD: 0.7692307692307693\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import OneClassSVM\n",
    "import numpy as np\n",
    "\n",
    "# Dividir los datos en conjunto de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test, indices_train, indices_test = train_test_split(df['abstract_p'], df['cell_line'], df.index, test_size=0.2, random_state=42)\n",
    "\n",
    "# Obtener el corpus y convertirlo en una lista\n",
    "corpus_train = X_train.tolist()\n",
    "corpus_test = X_test.tolist()\n",
    "\n",
    "# Crear el objeto vectorizador TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(corpus_train)\n",
    "X_test_tfidf = vectorizer.transform(corpus_test)\n",
    "\n",
    "category_labels_train = y_train.tolist()  # Convertir la columna a una lista\n",
    "category_labels_test = y_test.tolist()\n",
    "\n",
    "# Número de categorías\n",
    "num_categories = 12\n",
    "\n",
    "# Diccionarios para almacenar los centroides y radios por categoría\n",
    "category_centroids = {}\n",
    "category_radii = {}\n",
    "category_document_counts = {}\n",
    "\n",
    "for category in set(category_labels_train):\n",
    "    # Obtener los índices de los documentos correspondientes a la categoría actual en el conjunto de entrenamiento\n",
    "    category_indices_train = [i for i, label in enumerate(category_labels_train) if label == category]\n",
    "\n",
    "    if len(category_indices_train) > 0:\n",
    "        # Obtener los documentos correspondientes a la categoría actual en el conjunto de entrenamiento\n",
    "        category_documents_train = X_train_tfidf[category_indices_train]\n",
    "\n",
    "        # Entrenar el modelo SVDD para la categoría actual en el conjunto de entrenamiento\n",
    "        model = OneClassSVM(nu=0.1, kernel=\"rbf\", gamma=0.1)\n",
    "        model.fit(category_documents_train)\n",
    "\n",
    "        # Obtener los vectores de soporte del modelo\n",
    "        support_vectors = model.support_vectors_\n",
    "\n",
    "        # Calcular el centroide\n",
    "        centroid = np.mean(support_vectors, axis=0)\n",
    "        category_centroids[category] = centroid\n",
    "\n",
    "        # Calcular el radio (distancia promedio entre los vectores de soporte y el centroide)\n",
    "        distances = np.linalg.norm(support_vectors - centroid, axis=1)\n",
    "        radius = np.mean(distances)\n",
    "        category_radii[category] = radius\n",
    "\n",
    "        # Contar la cantidad de documentos en el centroide\n",
    "        document_count = len(category_indices_train)\n",
    "        category_document_counts[category] = document_count\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "predictions = []\n",
    "for i, doc in enumerate(X_test_tfidf):\n",
    "    min_distance = float('inf')\n",
    "    predicted_category = None\n",
    "    for category in set(category_labels_train):\n",
    "        # Calcular la distancia del documento al centroide de la categoría\n",
    "        distance = np.linalg.norm(doc - category_centroids[category])\n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            predicted_category = category\n",
    "    predictions.append(predicted_category)\n",
    "\n",
    "# Calcular la precisión del modelo SVDD en el conjunto de prueba\n",
    "accuracy = sum(y_test == predictions) / len(y_test)\n",
    "print(\"Precisión del modelo SVDD:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "220b750d-481f-4f75-9f1d-3ff764f6aa8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo SVDD: 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Dividir los datos en conjunto de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['abstract_p'], df['cell_line'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Obtener el corpus y convertirlo en una lista\n",
    "corpus_train = X_train.tolist()\n",
    "corpus_test = X_test.tolist()\n",
    "\n",
    "# Crear el objeto vectorizador TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(corpus_train)\n",
    "X_test_tfidf = vectorizer.transform(corpus_test)\n",
    "\n",
    "# Entrenar el modelo SVDD con los hiperparámetros especificados\n",
    "model = OneClassSVM(nu=0.1, kernel=\"rbf\", gamma=0.1)\n",
    "model.fit(X_train_tfidf)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "predictions = model.predict(X_test_tfidf)\n",
    "\n",
    "# Calcular la precisión del modelo en el conjunto de prueba\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Precisión del modelo SVDD:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "48c69e17-b027-460a-a8e9-1e38c117692e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categoría: CVCL_0081\n",
      "Centro de la hiperesfera: [[0. 0. 0. ... 0. 0. 0.]]\n",
      "Radio de la hiperesfera: 0.8650740307078411\n",
      "\n",
      "Categoría: CVCL_0082\n",
      "Centro de la hiperesfera: [[0. 0. 0. ... 0. 0. 0.]]\n",
      "Radio de la hiperesfera: 0.8486529514178892\n",
      "\n",
      "Categoría: CVCL_0110\n",
      "Centro de la hiperesfera: [[0. 0. 0. ... 0. 0. 0.]]\n",
      "Radio de la hiperesfera: 0.9249437746941228\n",
      "\n",
      "Categoría: CVCL_0028\n",
      "Centro de la hiperesfera: [[0.         0.         0.         ... 0.         0.         0.00490632]]\n",
      "Radio de la hiperesfera: 0.9171292891712453\n",
      "\n",
      "Categoría: CVCL_0113\n",
      "Centro de la hiperesfera: [[0. 0. 0. ... 0. 0. 0.]]\n",
      "Radio de la hiperesfera: 0.8943721506998026\n",
      "\n",
      "Categoría: CVCL_0115\n",
      "Centro de la hiperesfera: [[0. 0. 0. ... 0. 0. 0.]]\n",
      "Radio de la hiperesfera: 0.8932666768554471\n",
      "\n",
      "Categoría: CVCL_0080\n",
      "Centro de la hiperesfera: [[0.         0.         0.         ... 0.         0.         0.00819205]]\n",
      "Radio de la hiperesfera: 0.91930633449714\n",
      "\n",
      "Categoría: CVCL_0107\n",
      "Centro de la hiperesfera: [[0.00709729 0.         0.         ... 0.         0.         0.00445876]]\n",
      "Radio de la hiperesfera: 0.9076210890724002\n",
      "\n",
      "Categoría: CVCL_0128\n",
      "Centro de la hiperesfera: [[0. 0. 0. ... 0. 0. 0.]]\n",
      "Radio de la hiperesfera: 0.7771300135215716\n",
      "\n",
      "Categoría: CVCL_0135\n",
      "Centro de la hiperesfera: [[0.         0.10528045 0.01696511 ... 0.         0.         0.00470507]]\n",
      "Radio de la hiperesfera: 0.8965873865216044\n",
      "\n",
      "Categoría: CVCL_0138\n",
      "Centro de la hiperesfera: [[0. 0. 0. ... 0. 0. 0.]]\n",
      "Radio de la hiperesfera: 0.609988172364459\n",
      "\n",
      "Categoría: CVCL_0136\n",
      "Centro de la hiperesfera: [[0.         0.         0.         ... 0.00599232 0.0199784  0.00444956]]\n",
      "Radio de la hiperesfera: 0.8784825048512557\n",
      "\n",
      "Precisión del modelo SVDD: 0.7692307692307693\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import OneClassSVM\n",
    "import numpy as np\n",
    "\n",
    "# Dividir los datos en conjunto de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test, indices_train, indices_test = train_test_split(df['abstract_p'], df['cell_line'], df.index, test_size=0.2, random_state=42)\n",
    "\n",
    "# Obtener el corpus y convertirlo en una lista\n",
    "corpus_train = X_train.tolist()\n",
    "corpus_test = X_test.tolist()\n",
    "\n",
    "# Crear el objeto vectorizador TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(corpus_train)\n",
    "X_test_tfidf = vectorizer.transform(corpus_test)\n",
    "\n",
    "category_labels_train = y_train.tolist()  # Convertir la columna a una lista\n",
    "category_labels_test = y_test.tolist()\n",
    "\n",
    "# Número de categorías\n",
    "num_categories = 12\n",
    "\n",
    "# Diccionarios para almacenar los centros y radios por categoría\n",
    "category_centers = {}\n",
    "category_radii = {}\n",
    "category_document_counts = {}\n",
    "\n",
    "for category in set(category_labels_train):\n",
    "    # Obtener los índices de los documentos correspondientes a la categoría actual en el conjunto de entrenamiento\n",
    "    category_indices_train = [i for i, label in enumerate(category_labels_train) if label == category]\n",
    "\n",
    "    if len(category_indices_train) > 0:\n",
    "        # Obtener los documentos correspondientes a la categoría actual en el conjunto de entrenamiento\n",
    "        category_documents_train = X_train_tfidf[category_indices_train]\n",
    "\n",
    "        # Entrenar el modelo SVDD para la categoría actual en el conjunto de entrenamiento\n",
    "        model = OneClassSVM(nu=0.1, kernel=\"rbf\", gamma=\"scale\")\n",
    "        model.fit(category_documents_train)\n",
    "\n",
    "        # Obtener los vectores de soporte del modelo\n",
    "        support_vectors = model.support_vectors_\n",
    "\n",
    "        # Calcular el centro de la hiperesfera como el vector medio de los vectores de soporte\n",
    "        center = np.mean(support_vectors, axis=0)\n",
    "        category_centers[category] = center\n",
    "\n",
    "        # Calcular el radio de la hiperesfera como la distancia media entre los vectores de soporte y el centro\n",
    "        distances = np.linalg.norm(support_vectors - center, axis=1)\n",
    "        radius = np.mean(distances)\n",
    "        category_radii[category] = radius\n",
    "\n",
    "        # Contar la cantidad de documentos en la hiperesfera\n",
    "        document_count = len(category_indices_train)\n",
    "        category_document_counts[category] = document_count\n",
    "\n",
    "# Imprimir los resultados\n",
    "for category in set(category_labels_train):\n",
    "    print(\"Categoría:\", category)\n",
    "    print(\"Centro de la hiperesfera:\", category_centers[category])\n",
    "    print(\"Radio de la hiperesfera:\", category_radii[category])\n",
    "    print()\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "predictions = []\n",
    "for i, doc in enumerate(X_test_tfidf):\n",
    "    min_distance = float('inf')\n",
    "    predicted_category = None\n",
    "    for category in set(category_labels_train):\n",
    "        # Calcular la distancia del documento al centro de la hiperesfera\n",
    "        distance = np.linalg.norm(doc - category_centers[category])\n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            predicted_category = category\n",
    "    predictions.append(predicted_category)\n",
    "\n",
    "accuracy = sum(y_test == predictions) / len(y_test)\n",
    "print(\"Precisión del modelo SVDD:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78f8c7b-200b-4588-b6ef-61bfbf89ba43",
   "metadata": {},
   "source": [
    "## Matriz de distancias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "88a6230b-a842-4a19-80cd-680ceb40bf34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.]\n",
      "(12, 1, 3208)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[0.        , 0.        , 0.        , ..., 0.        ,\n",
       "         0.        , 0.        ]],\n",
       "\n",
       "       [[0.        , 0.        , 0.        , ..., 0.        ,\n",
       "         0.        , 0.        ]],\n",
       "\n",
       "       [[0.        , 0.        , 0.        , ..., 0.        ,\n",
       "         0.        , 0.        ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.        , 0.10528045, 0.01696511, ..., 0.        ,\n",
       "         0.        , 0.00470507]],\n",
       "\n",
       "       [[0.        , 0.        , 0.        , ..., 0.        ,\n",
       "         0.        , 0.        ]],\n",
       "\n",
       "       [[0.        , 0.        , 0.        , ..., 0.00599232,\n",
       "         0.0199784 , 0.00444956]]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centers = np.array(list(category_centers.values()))\n",
    "origin  = np.zeros(centers.shape[1])\n",
    "print(origin)\n",
    "vectors_to_centers = centers - origin\n",
    "print(vectors_to_centers.shape)\n",
    "\n",
    "distances = np.zeros((num_categories, num_categories))\n",
    "vectors_to_centers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
